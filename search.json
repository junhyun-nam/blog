[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal ML Paper Study",
    "section": "",
    "text": "Diffusion Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Paper Summary\n\n\n\n\n\n\n\n\nAug 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDiffusion model basics\n\n\n\n\n\n\n\n\nAug 8, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/category-diffusion.html",
    "href": "posts/category-diffusion.html",
    "title": "Diffusion Models",
    "section": "",
    "text": "여기는 Diffusion Models 분야 논문 정리 페이지입니다.\n\nBasics",
    "crumbs": [
      "Home",
      "Topics",
      "Diffusion models"
    ]
  },
  {
    "objectID": "posts/2025-08-08-first-post.html",
    "href": "posts/2025-08-08-first-post.html",
    "title": "My First Paper Summary",
    "section": "",
    "text": "논문 요약 작성 예시입니다.\n\n\n\n주요 기여점\n기술적 접근\n실험 결과\n\n수식 예시:\n\\[\n\\mathcal{L} = \\sum_i (y_i - \\hat{y}_i)^2\n\\]\n```python # 예시 코드 블록 import torch print(torch.__version__)"
  },
  {
    "objectID": "posts/2025-08-08-first-post.html#key-ideas",
    "href": "posts/2025-08-08-first-post.html#key-ideas",
    "title": "My First Paper Summary",
    "section": "",
    "text": "주요 기여점\n기술적 접근\n실험 결과\n\n수식 예시:\n\\[\n\\mathcal{L} = \\sum_i (y_i - \\hat{y}_i)^2\n\\]\n```python # 예시 코드 블록 import torch print(torch.__version__)"
  },
  {
    "objectID": "posts/2025-08-08-diffusion-basics.html",
    "href": "posts/2025-08-08-diffusion-basics.html",
    "title": "Diffusion model basics",
    "section": "",
    "text": "Diffusion model의 시초는 Sohl-Dickstein의 diffusion probablistic model (Sohl-Dickstein et al., 2015).\n이후 Yang Song의 noise-conditioned score network (NCSN, a.k.a., score matching; Yang & Ermon, 2019)과 Jonathan Ho의 denoising diffusion probabilistic model (DDPM; Ho et al., 2020) 부터 그 당시 SOTA 였던 GAN과 comparable한 성능을 보여주기 시작하면서 가능성을 주목받기 시작함.\n기본적으로 GAN이나 flow-based model이 그렇듯, 어떤 tractable distribution (e.g., Gaussian)과 data distribution 간의 mapping을 잘 모델링 해서, tractable distribution으로 부터 sampling한 \\(z\\)로 부터 data distribution의 \\(x\\)를 생성하는 것이 목표임.\nDiffusion model은 이러한 mapping을 data distribution의 \\(x\\)에 아주 작은 양의 Gaussian noise를 계속 더해서 \\(x\\)와 같은 dimension을 가지는 Gaussian random variable로 mapping 하고, 이러한 과정을 역으로 mapping 할 수 있는 function을 학습을 해서 \\(z\\)로 부터 \\(x\\)를 생성함"
  },
  {
    "objectID": "posts/2025-08-08-diffusion-basics.html#forward-diffusion-process",
    "href": "posts/2025-08-08-diffusion-basics.html#forward-diffusion-process",
    "title": "Diffusion model basics",
    "section": "Forward Diffusion Process",
    "text": "Forward Diffusion Process"
  },
  {
    "objectID": "posts/2025-08-08-diffusion-basics.html#key-ideas",
    "href": "posts/2025-08-08-diffusion-basics.html#key-ideas",
    "title": "Diffusion model basics",
    "section": "Key Ideas",
    "text": "Key Ideas\n\n주요 기여점\n기술적 접근\n실험 결과\n\n수식 예시:\n\\[\n\\mathcal{L} = \\sum_i (y_i - \\hat{y}_i)^2\n\\]\n```python # 예시 코드 블록 import torch print(torch.__version__)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "이 블로그는 아이패드에서도 바로 편집 가능하도록\nGitHub Codespaces와 Quarto를 사용해 제작되었습니다."
  }
]